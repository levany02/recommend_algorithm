{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b2ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4779cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randint(0, 100, (100, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f444cb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "\n",
    "        # The embedding layer converts tokens to vectors\n",
    "        self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
    "                                                   embedding_dim)\n",
    "\n",
    "        # The GRU RNN layer processes those vectors sequentially.\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       # Return the sequence and state\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, tokens, state=None):\n",
    "#         shape_checker = ShapeChecker()\n",
    "#         shape_checker(tokens, ('batch', 's'))\n",
    "\n",
    "        # 2. The embedding layer looks up the embedding for each token.\n",
    "        vectors = self.embedding(tokens)\n",
    "#         shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
    "\n",
    "        # 3. The GRU processes the embedding sequence.\n",
    "        #    output shape: (batch, s, enc_units)\n",
    "        #    state shape: (batch, enc_units)\n",
    "        output, state = self.gru(vectors, initial_state=state)\n",
    "#         shape_checker(output, ('batch', 's', 'enc_units'))\n",
    "#         shape_checker(state, ('batch', 'enc_units'))\n",
    "\n",
    "        # 4. Returns the new sequence and its state.\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "782a7c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "units = 1024\n",
    "\n",
    "encoder = Encoder(100, 256, 1024)\n",
    "ex_encode_output, ex_encode_state = encoder(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8854da07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([100, 5, 1024]), TensorShape([100, 1024]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_encode_output.shape, ex_encode_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19feb75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        # For Eqn. (4), the  Bahdanau attention\n",
    "        self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "\n",
    "        self.attention = tf.keras.layers.AdditiveAttention()\n",
    "\n",
    "    def call(self, query, value, mask):\n",
    "#         shape_checker = ShapeChecker()\n",
    "#         shape_checker(query, ('batch', 't', 'query_units'))\n",
    "#         shape_checker(value, ('batch', 's', 'value_units'))\n",
    "#         shape_checker(mask, ('batch', 's'))\n",
    "\n",
    "        # From Eqn. (4), `W1@ht`.\n",
    "        w1_query = self.W1(query)\n",
    "#         shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
    "\n",
    "        # From Eqn. (4), `W2@hs`.\n",
    "        w2_key = self.W2(value)\n",
    "#         shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
    "\n",
    "        query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
    "        value_mask = mask\n",
    "\n",
    "        context_vector, attention_weights = self.attention(\n",
    "            inputs = [w1_query, value, w2_key],\n",
    "            mask=[query_mask, value_mask],\n",
    "            return_attention_scores = True,\n",
    "        )\n",
    "#         shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
    "#         shape_checker(attention_weights, ('batch', 't', 's'))\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2815e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_layer = BahdanauAttention(units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "009a55fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data != 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55e8a94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch_size, query_seq_length, units):           (100, 2, 1024)\n",
      "Attention weights shape: (batch_size, query_seq_length, value_seq_length): (100, 2, 5)\n"
     ]
    }
   ],
   "source": [
    "# Later, the decoder will generate this attention query\n",
    "example_attention_query = tf.random.normal(shape=[len(data), 2, 10])\n",
    "\n",
    "# Attend to the encoded tokens\n",
    "\n",
    "context_vector, attention_weights = attention_layer(\n",
    "    query=example_attention_query,\n",
    "    value=ex_encode_output,\n",
    "    mask=(data != 0))\n",
    "\n",
    "print(f'Attention result shape: (batch_size, query_seq_length, units):           {context_vector.shape}')\n",
    "print(f'Attention weights shape: (batch_size, query_seq_length, value_seq_length): {attention_weights.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b02906f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 2, 5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ba149ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.output_vocab_size = output_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # For Step 1. The embedding layer convets token IDs to vectors\n",
    "        self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
    "                                                   embedding_dim)\n",
    "\n",
    "        # For Step 2. The RNN keeps track of what's been generated so far.\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "        # For step 3. The RNN output will be the query for the attention layer.\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "        # For step 4. Eqn. (3): converting `ct` to `at`\n",
    "        self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
    "                                        use_bias=False)\n",
    "\n",
    "        # For step 5. This fully connected layer produces the logits for each\n",
    "        # output token.\n",
    "        self.fc = tf.keras.layers.Dense(self.output_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9d3c07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "from typing import Any, Tuple\n",
    "\n",
    "class DecoderInput(typing.NamedTuple):\n",
    "    new_tokens: Any\n",
    "    enc_output: Any\n",
    "    mask: Any\n",
    "\n",
    "class DecoderOutput(typing.NamedTuple):\n",
    "    logits: Any\n",
    "    attention_weights: Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2dd262b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call(self,\n",
    "         inputs: DecoderInput,\n",
    "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
    "    vectors = self.embedding(inputs.new_tokens)\n",
    "    \n",
    "    rnn_output, state = self.gru(vectors, initial_state=state)\n",
    "    print(\"Hello world\")\n",
    "    print(rnn_output)\n",
    "    \n",
    "    context_vector, attention_weights = self.attention(\n",
    "      query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
    "    context_and_rnn_output = context_vector\n",
    "    attention_vector = self.Wc(context_and_rnn_output)\n",
    "    logits = self.fc(attention_vector)\n",
    "    return DecoderOutput(logits, attention_weights), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d65e3d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Decoder.call = call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b2ae8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(100, embedding_dim, units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f012cbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n",
      "tf.Tensor(\n",
      "[[[-6.67360332e-03  1.58940423e-02  7.53728114e-03 ...  5.91070578e-03\n",
      "   -6.21128175e-03  1.41745375e-03]]\n",
      "\n",
      " [[-1.07842200e-02  1.24648772e-02  6.80857105e-04 ...  4.60236892e-03\n",
      "    3.35511356e-03  1.41524838e-03]]\n",
      "\n",
      " [[-9.22174286e-03  7.77802430e-03  5.61453914e-03 ...  1.14401691e-02\n",
      "   -4.61135665e-03 -1.67042250e-04]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-5.00767538e-03  9.74254124e-03  5.27418358e-03 ...  1.18234633e-02\n",
      "    9.50882491e-03  2.69417092e-03]]\n",
      "\n",
      " [[-2.22809007e-03  6.96638180e-03  2.26637488e-03 ...  7.26535823e-03\n",
      "   -2.24366202e-03 -5.79853076e-05]]\n",
      "\n",
      " [[-6.45158347e-03  1.34356488e-02  4.12107119e-03 ...  1.05279125e-02\n",
      "   -3.18481121e-04 -2.19650287e-03]]], shape=(100, 1, 1024), dtype=float32)\n",
      "logits shape: (batch_size, t, output_vocab_size) (100, 1, 100)\n",
      "state shape: (batch_size, dec_units) (100, 1024)\n"
     ]
    }
   ],
   "source": [
    "first_token = tf.constant([[0]] * data.shape[0])\n",
    "\n",
    "dec_result, dec_state = decoder(\n",
    "    inputs = DecoderInput(new_tokens=first_token,\n",
    "                          enc_output=ex_encode_output,\n",
    "                          mask=(data != 0)),\n",
    "    state = ex_encode_state\n",
    ")\n",
    "\n",
    "print(f'logits shape: (batch_size, t, output_vocab_size) {dec_result.logits.shape}')\n",
    "print(f'state shape: (batch_size, dec_units) {dec_state.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3df84fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bde6a034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
       "array([[45],\n",
       "       [ 6],\n",
       "       [95],\n",
       "       [36],\n",
       "       [57]])>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_token[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1705beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        self.name = 'masked_loss'\n",
    "        self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=True, reduction='none')\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "#         shape_checker = ShapeChecker()\n",
    "#         shape_checker(y_true, ('batch', 't'))\n",
    "#         shape_checker(y_pred, ('batch', 't', 'logits'))\n",
    "\n",
    "        # Calculate the loss for each item in the batch.\n",
    "        loss = self.loss(y_true, y_pred)\n",
    "#         shape_checker(loss, ('batch', 't'))\n",
    "\n",
    "        # Mask off the losses on padding.\n",
    "        mask = tf.cast(y_true != 0, tf.float32)\n",
    "#         shape_checker(mask, ('batch', 't'))\n",
    "        loss *= mask\n",
    "\n",
    "        # Return the total.\n",
    "        return tf.reduce_sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c37203fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommendation(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, units,\n",
    "               input_text_processor,\n",
    "               output_text_processor, \n",
    "               use_tf_function=True):\n",
    "        super().__init__()\n",
    "        # Build the encoder and decoder\n",
    "        encoder = Encoder(5000, embedding_dim, units)\n",
    "        decoder = Decoder(5000, embedding_dim, units)\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.input_text_processor = input_text_processor\n",
    "        self.output_text_processor = output_text_processor\n",
    "        self.use_tf_function = use_tf_function\n",
    "#         self.shape_checker = ShapeChecker()\n",
    "\n",
    "    def train_step(self, inputs):\n",
    "#         self.shape_checker = ShapeChecker()\n",
    "        if self.use_tf_function:\n",
    "            return self._tf_train_step(inputs)\n",
    "        else:\n",
    "            return self._train_step(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b4e350e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess(self, input_tokens, target_tokens):\n",
    "\n",
    "    # Convert the text to token IDs\n",
    "#     input_tokens = self.input_text_processor(input_text)\n",
    "#     target_tokens = self.output_text_processor(target_text)\n",
    "#     self.shape_checker(input_tokens, ('batch', 's'))\n",
    "#     self.shape_checker(target_tokens, ('batch', 't'))\n",
    "\n",
    "    # Convert IDs to masks.\n",
    "    input_mask = input_tokens != 0\n",
    "#     self.shape_checker(input_mask, ('batch', 's'))\n",
    "\n",
    "    target_mask = target_tokens != 0\n",
    "#     self.shape_checker(target_mask, ('batch', 't'))\n",
    "\n",
    "    return input_tokens, input_mask, target_tokens, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e74fa863",
   "metadata": {},
   "outputs": [],
   "source": [
    "Recommendation._preprocess = _preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "daf6651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_step(self, inputs):\n",
    "    input_text, target_text = inputs  \n",
    "\n",
    "    (input_tokens, input_mask,\n",
    "    target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
    "\n",
    "    max_target_length = tf.shape(target_tokens)[1]\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Encode the input\n",
    "        enc_output, enc_state = self.encoder(input_tokens)\n",
    "#         self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
    "#         self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
    "\n",
    "        # Initialize the decoder's state to the encoder's final state.\n",
    "        # This only works if the encoder and decoder have the same number of\n",
    "        # units.\n",
    "        dec_state = enc_state\n",
    "        loss = tf.constant(0.0)\n",
    "\n",
    "        for t in tf.range(max_target_length-1):\n",
    "            new_tokens = target_tokens[:, t:t+2]\n",
    "            step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
    "                                                 enc_output, dec_state)\n",
    "            loss = loss + step_loss\n",
    "\n",
    "        # Average the loss over all non padding tokens.\n",
    "        average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
    "\n",
    "    # Apply an optimization step\n",
    "    variables = self.trainable_variables \n",
    "    gradients = tape.gradient(average_loss, variables)\n",
    "    self.optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    # Return a dict mapping metric names to current value\n",
    "    return {'batch_loss': average_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "17b1046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Recommendation._train_step = _train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb2bd3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
    "    input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
    "\n",
    "    # Run the decoder one step.\n",
    "    decoder_input = DecoderInput(new_tokens=input_token,\n",
    "                               enc_output=enc_output,\n",
    "                               mask=input_mask)\n",
    "\n",
    "    dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
    "#     self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n",
    "#     self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
    "#     self.shape_checker(dec_state, ('batch', 'dec_units'))\n",
    "\n",
    "    # `self.loss` returns the total for non-padded tokens\n",
    "    y = target_token\n",
    "    y_pred = dec_result.logits\n",
    "    step_loss = self.loss(y, y_pred)\n",
    "\n",
    "    return step_loss, dec_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c009a63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Recommendation._loop_step = _loop_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d59366b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.random.randint(0, 5000, size=(10000, 10))\n",
    "target_data = np.random.randint(0, 5000, size=(10000, 10))\n",
    "\n",
    "\n",
    "translator = Recommendation(\n",
    "    embedding_dim, units,\n",
    "    input_text_processor=None,\n",
    "    output_text_processor=None,\n",
    "    use_tf_function=False)\n",
    "\n",
    "# Configure the loss and optimizer\n",
    "translator.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    loss=MaskedLoss(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ce2a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for n in range(10):\n",
    "    print(translator.train_step([input_data, target_data]))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
